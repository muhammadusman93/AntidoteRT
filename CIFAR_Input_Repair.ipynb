{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-Original.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2OoE2eBYY88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc13b4ad-2bd1-4546-d9ad-80de8995cc96"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#drive.flush_and_unmount()\n",
        "#!rm -rf /content/drive\n",
        "import time\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "535NiEnj4UEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8279b6-7fe6-407f-c895-9478030e58ed"
      },
      "source": [
        "!pip install tf-keras-vis\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"GradCam.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1cKjutZfO-CAwKnI4E84NAhm4seqoyGi0\n",
        "\"\"\"\n",
        "\n",
        "#!pip install tf-keras-vis\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import time\n",
        "#from Models.loss import smoothL1\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Input, InputLayer\n",
        "from tensorflow.keras.layers import Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.gradcam import GradcamPlusPlus\n",
        "\n",
        "from tf_keras_vis.utils import normalize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "import math\n",
        "import io\n",
        "import os\n",
        "from collections import namedtuple\n",
        "import sys\n",
        "\n",
        "import operator\n",
        "\n",
        "import copy\n",
        "\n",
        "#from tf_keras_vis.utils import num_of_gpus\n",
        "\n",
        "#_, gpus = num_of_gpus()\n",
        "#print('{} GPUs'.format(gpus))\n",
        "!pwd\n",
        "os.chdir(\"./drive/MyDrive\")\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "from platform import python_version\n",
        "\n",
        "print(python_version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-keras-vis\n",
            "  Downloading tf_keras_vis-0.8.0-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 20 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 37.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 40 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 51 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tf-keras-vis) (1.4.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from tf-keras-vis) (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-keras-vis) (7.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from tf-keras-vis) (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-keras-vis) (21.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->tf-keras-vis) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio->tf-keras-vis) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->tf-keras-vis) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->tf-keras-vis) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-keras-vis) (2.4.7)\n",
            "Installing collected packages: deprecated, tf-keras-vis\n",
            "Successfully installed deprecated-1.2.13 tf-keras-vis-0.8.0\n",
            "/content\n",
            "/content/drive/MyDrive\n",
            " 1537388756095_chk-train0-0out.gdoc\n",
            " 20-neurons-low-quality.gdoc\n",
            "'27204 NIW Evidence Package Scan.pdf'\n",
            " ACASX_LAYER0.gdoc\n",
            " ACASX_LAYER1.gdoc\n",
            " anchor-master.zip\n",
            " Anchors_DPs_maxpool5.csv.gdoc\n",
            " Anchors_DPs_p5.gsheet\n",
            " Anchors.gsheet\n",
            " Anchors_p5_imp_features.gsheet\n",
            " anchors_refined.gsheet\n",
            " Anchors_WB.gsheet\n",
            "'April 05 2019 pay stub.pdf'\n",
            "'April 14 2019 pay stub.pdf'\n",
            "'Areas of interests.pptx'\n",
            "'ArtinAction -Lesson 1'\n",
            "'aRT IN ACTION -lESSON 1.gdoc'\n",
            "'ASE 2019.pptx'\n",
            "'ASE PRESENTATION.pptx'\n",
            "'ASE Registration.gdoc'\n",
            "'ASE TRIP EXPENSES.gsheet'\n",
            " ATT00003.gdoc\n",
            "'boeing demo_Trim1.mp4'\n",
            " BoeingDemoV1.gdoc\n",
            " BoeingDemoV1.pdf\n",
            " Boeing.gslides\n",
            "'Boeing Presentation.gslides'\n",
            "'Boeing Presentation.pptx'\n",
            "'BOEING TAXINET TRAIN SAFETY LT 4 AND CORRECTNESS .docx'\n",
            " Callisto.gdoc\n",
            "'chk-train0-0out (1).gdoc'\n",
            "'chk-train0-0out (2).gdoc'\n",
            " chk-train0-0out.gdoc\n",
            " cifar6.png\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Concolic_Attribution\n",
            " constraints-0.0op.txt\n",
            " constraints-0.1op.txt\n",
            " constraints-0-2op.txt\n",
            " constraints-0-3op.txt\n",
            "'Copy of FMCAD rebuttal.gdoc'\n",
            "'Copy of FMCAD Rebuttal.gdoc'\n",
            "'Copy of ICSE 2021 - Repair Project.gdoc'\n",
            "'Copy of Infosys2020_Explainability.gslides'\n",
            "'Copy of TaxiNet Analysis Discussion.gslides'\n",
            " CV_Resume.docx\n",
            "'Dec 28 2018 paystub.pdf'\n",
            "'DeepContract MOM'\n",
            " DeepSAFE.pdf\n",
            "'DemoBoeing2Formatted_1 (1).pptx'\n",
            "'DemoBoeing2Formatted_1 (2).pptx'\n",
            " DemoBoeing2Formatted_1.pdf\n",
            " DemoBoeing2Formatted_1.pptx\n",
            " DemoBoeing2Formatted.pptx\n",
            " DemoBoeing2.gslides\n",
            " DemoBoeing2.pptx\n",
            "'Demo Video (1).mp4'\n",
            "'Demo Video.mp4'\n",
            " DivyaGopinath.pdf\n",
            " DivyaGopinathResumeLatest.pdf\n",
            "'DNN Repair.gdoc'\n",
            " EAD.pdf\n",
            "'EASA guidelines Notes.gdoc'\n",
            "'Employement verification with salary and Bonus.pdf'\n",
            "'Employment Verification Letter NIW.docx'\n",
            " ETA750B_1.pdf\n",
            "'ETA-750B_27204_to be revised and signed.pdf'\n",
            " ETA750B_2.pdf\n",
            " ETA750B_3.pdf\n",
            " Europa.gdoc\n",
            " Europa.txt\n",
            "'Family game night.mp4'\n",
            "'Feb 22 2019 Pay stub.pdf'\n",
            " File_20200226-185632.pdf\n",
            "'Finalized Forms_27204.pdf'\n",
            "'FMCAD Rebuttal.gdoc'\n",
            " four_car_testset.gsheet\n",
            "'four_car_train_BB (1).csv.gdoc'\n",
            "'four_car_train_BB (2).csv.gdoc'\n",
            " four_car_train_BB.csv.gdoc\n",
            " four_car_train_BB_IMP.gsheet\n",
            " four_car_train_DP.gsheet\n",
            " four_car_train_DP_IMP.gsheet\n",
            "'Gmail - Honda registration.pdf'\n",
            "'GreenCard Filing'\n",
            " Gundu.txt.gdoc\n",
            "'h4 approval.pdf'\n",
            " Hu_etal_ACL16.pdf\n",
            "'I-140 Filing from Home Instructions.pdf'\n",
            " ICCV15_DeepNDF_main.pdf\n",
            "'Ideas Related to Boeing Project.gdoc'\n",
            "'ID front.jpg'\n",
            "'IJCAI 2019 rebuttal.gdoc'\n",
            " Infosys2020_Explainability.gslides\n",
            " InfoSys2020.gslides\n",
            " InfoSys2020.pptx\n",
            " Infy2020_v1.gslides\n",
            " Infy2020_v1.pptx\n",
            " InfyQA_Explainability.gslides\n",
            " InfyQA_v2.gslides\n",
            "'Insurance ID Card - 2017-06-16 (1).pdf'\n",
            "'Insurance ID Card - 2017-06-16 (2).pdf'\n",
            "'Insurance ID Card - 2017-06-16.pdf'\n",
            "'Insurance ID Card - 2017-12-16 (1).pdf'\n",
            "'Insurance ID Card - 2017-12-16.pdf'\n",
            "'Inventory Tracking For thoppai and Gundu.gsheet'\n",
            "'ISSRE 2019 camera ready.gdoc'\n",
            " issre.zip\n",
            " issta18-paper62.pdf\n",
            "'ISSTA responses.gdoc'\n",
            "'Jan 18 2019 Pay stub.pdf'\n",
            "'Jan 25 2019 Pay Stub.pdf'\n",
            " KJ-TrainArtifacts.zip\n",
            "'Latest (2019) I797.pdf'\n",
            "'Latest ASE 2019.pdf'\n",
            "'Latest ASE 2019.pptx'\n",
            " LFWmodel.h5\n",
            " Liam\n",
            "'March 03 2019.pdf'\n",
            "'March 22 2019 Pay stub.pdf'\n",
            "'Math questions from the goblet of farts from the merlin series from the pee and poo and farts and dumb people.gdoc'\n",
            "'MathQuestions_the sorcerers buttstink.gdoc'\n",
            "'Minutes of Meetings.gdoc'\n",
            " mnist_3A_layer.txt.gdoc\n",
            " mnist_deep_sym_coeffs_0_mult_input.gdoc\n",
            " MNIST_GEN_SET_50_0.txt\n",
            " MNIST_GEN_SET_LABELS_50_0.txt\n",
            "'mnist_input_image_0 (1).gdoc'\n",
            " mnist_input_image_0.gdoc\n",
            " mnist_train_csv.txt\n",
            " mnist_train_label_csv.txt\n",
            " MNIST_VAL_SET_50_0.txt\n",
            " MNIST_VAL_SET_LABELS_50_0.txt\n",
            "'My Performance History.pdf'\n",
            "'My Saved Places.gmap'\n",
            "'My story.docx'\n",
            "'Naresh latest I-94.pdf'\n",
            " Naresh_Passport_all_pages.pdf\n",
            "'NASA Internship Poster.key'\n",
            "'Nikhils school homework plan.gdoc'\n",
            "'Nikhil Venkat - Informative Writing Pre-Assessment.pdf'\n",
            "'Nikhil Venkat - Passion Share Script and Guidelines.pdf'\n",
            " NikkuBday.mov\n",
            " NNConstraintSolving.java\n",
            "'Numbers by nikhil.gsheet'\n",
            " one_car_testset.gsheet\n",
            "'p1_dps (1).gsheet'\n",
            " p1_dps.gsheet\n",
            " p5_dps.gsheet\n",
            " p5_dps_imp_features.gsheet\n",
            " ProfilePicture.jpg\n",
            " propertyFiles.gdoc\n",
            " propertyFiles.txt\n",
            "'Property Inference for Deep Neural Networks.pdf'\n",
            "'ptest_test_val_rand (1).txt'\n",
            " ptest_test_val_rand_labels.txt\n",
            " ptest_test_val_rand.txt\n",
            " ReluplexCavClean-master.tar.gz\n",
            "'Repair Ideas..gdoc'\n",
            " Reviews\n",
            " Revised_indep_Kwiatkowska_Gopinath_27204_9.10.2019-MKedits.docx\n",
            " Revised_indep_Kwiatkowska_Gopinath_27204_9.10.2019-MKedits.gdoc\n",
            " RULES_TEST_VALIDATION.xlsx\n",
            "'RULES VALIDATION.gsheet'\n",
            "'SafeDNN: Property inference, probabilistic analysis and formal explanations for neural networks.gslides'\n",
            "'Safety Assurance, Computer based techniques .gdoc'\n",
            "'SHOPPING  LIST.gdoc'\n",
            "'Shopping List.gsheet'\n",
            "'Short ASE PRESENTATION.pptx'\n",
            "'SHORTER ASE PRESENTATION.gslides'\n",
            " shrt_out_0.gdoc\n",
            "'Sizes of planets.docx'\n",
            "'Summer internship 2021.gsheet'\n",
            "'Summer Internship Ideas .gdoc'\n",
            "'symbolic execution of DNN.pdf'\n",
            " TACAS_2018_paper_10.pdf\n",
            "'TaxiNet Analysis Discussion.gslides'\n",
            "'TaxiNet Analysis.gslides'\n",
            "'TAXINET PROJECT.gdoc'\n",
            "'Testing Deep Learning Algorithms'\n",
            "'testset (1).gsheet'\n",
            "'The distances of planets.docx'\n",
            "'The Upside-Down Man: A funny short story.gdoc'\n",
            "'THOP CHEMISTRY CLASS.gdoc'\n",
            "'ThoppaiGundu Adventures.gdoc'\n",
            " three_car_testset.gsheet\n",
            " train-images.idx3-ubyte\n",
            "'train-images-outNew (1).idx3-ubyte'\n",
            " train-images-outNew.idx3-ubyte\n",
            "'train-labels-outNew (1).idx1-ubyte'\n",
            " train-labels-outNew.idx1-ubyte\n",
            " two_car_testset.gsheet\n",
            "'two_car_trainset_DPs (1).gsheet'\n",
            " two_car_trainset_DPs.gsheet\n",
            " two_car_trainset.gsheet\n",
            " underapprox.tex\n",
            " Understanding_NN_arXiv.pdf\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled drawing.gdraw'\n",
            "'Untitled presentation.gslides'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet (2).gsheet'\n",
            "'Untitled spreadsheet (3).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " VID-20200615-WA0019.mp4\n",
            "'Week 5 - Discussion .gdoc'\n",
            " z3constraints\n",
            "2.6.0\n",
            "3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQM9MQCg-dfP"
      },
      "source": [
        "GENERATION_DATASETS = True\n",
        "num_run = 9\n",
        "N = 50 # 50%, 25%, 10%\n",
        "NP=25\n",
        "further=True\n",
        "further2=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0PYDo3x3089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "de272b6b-67ec-465e-9242-617ed8acda27"
      },
      "source": [
        "def get_prediction(img, tensor = None):\n",
        "  \n",
        "    if tensor == \"ALL\":\n",
        "        full_list = []\n",
        "        for tensor in ['dense_1', 'dense_2', 'dense_3']:\n",
        "            layer_name = tensor           \n",
        "            layer = model.get_layer(layer_name)\n",
        "            func = K.function(model.input, [layer.output])\n",
        "            imag = np.expand_dims(img,axis=0)\n",
        "            outputs = func(imag)\n",
        "           # print(outputs)\n",
        "            layer_outputs_test = []\n",
        "            fingerprint1 = ((outputs[0] > 0.0).astype('int'))\n",
        "            layer_outputs_test = []\n",
        "            layer_result = fingerprint1\n",
        "            layer_outputs_test.append(layer_result[0])\n",
        "            full_list.append(layer_outputs_test) \n",
        "            \n",
        "        new_list = [list(full_list[0][0])+list(full_list[1][0])+list(full_list[2][0])]\n",
        "        layer_outputs_test = np.asarray(new_list)\n",
        "        return layer_outputs_test\n",
        "    else:\n",
        "        layer_name = tensor\n",
        "        layer = model.get_layer(layer_name)\n",
        "        func = K.function(model.input, [layer.output])\n",
        "        imag = np.expand_dims(img,axis=0)\n",
        "        outputs = func(imag)\n",
        "       # print(outputs)\n",
        "        fingerprint1 = ((outputs[0] > 0.0).astype('int'))\n",
        "        layer_outputs_test = []\n",
        "        layer_result = fingerprint1\n",
        "        layer_outputs_test.append(layer_result[0])\n",
        "        layer_outputs_test = np.asarray(layer_outputs_test)     \n",
        "    \n",
        "        return layer_outputs_test\n",
        "\n",
        "def get_prediction_vals(img, tensor = None):\n",
        "  \n",
        "    if tensor == \"ALL\":\n",
        "        full_list = []\n",
        "        for tensor in ['activation_1','activation_2','activation_3']:\n",
        "            layer_name = tensor           \n",
        "            layer = model.get_layer(layer_name)\n",
        "            func = K.function(model.input, [layer.output])\n",
        "            imag = np.expand_dims(img,axis=0)\n",
        "            outputs = func(imag)\n",
        "            op = np.array(outputs)\n",
        "            #print(op.shape)\n",
        "            flat_op = op.flatten()\n",
        "            #print(flat_op.shape)\n",
        "            fingerprint1 = list(flat_op)\n",
        "            #print(layer.name,fingerprint1)\n",
        "            layer_outputs_test = []\n",
        "            layer_result = fingerprint1\n",
        "            layer_outputs_test.append(layer_result)\n",
        "            full_list.append(layer_outputs_test) \n",
        "            \n",
        "        new_list = [list(full_list[0][0])+list(full_list[1][0])+list(full_list[2][0])]\n",
        "        layer_outputs_test = np.asarray(new_list)\n",
        "        return layer_outputs_test\n",
        "    else:\n",
        "        layer_name = tensor\n",
        "        layer = model.get_layer(layer_name)\n",
        "        func = K.function(model.input, [layer.output])\n",
        "        imag = np.expand_dims(img,axis=0)\n",
        "        outputs = func(imag)\n",
        "       # print(outputs)\n",
        "        #fingerprint1 = ((outputs[0] > 0.0).astype('int'))\n",
        "        fingerprint1 = outputs[0]\n",
        "        layer_outputs_test = []\n",
        "        layer_result = fingerprint1\n",
        "        layer_outputs_test.append(layer_result[0])\n",
        "        layer_outputs_test = np.asarray(layer_outputs_test)     \n",
        "    \n",
        "        return layer_outputs_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fingerprint_suffix(img,ten):\n",
        "    return (get_prediction(img, tensor=ten)>0.0).astype('int')\n",
        "\n",
        "def fingerprint_suffix_vals(img,ten):\n",
        "    return get_prediction_vals(img, tensor=ten)\n",
        "\n",
        "#from tf_keras_vis.gradcam import Gradcam\n",
        "#from tf_keras_vis.gradcam import GradcamPlusPlus\n",
        "\n",
        "def model_modifier_act1_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='activation_1') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "def model_modifier_act2_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='activation_2') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "def model_modifier_act3_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='activation_3') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "def model_modifier_act5_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='activation_5') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def model_modifier_last_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='activation_4') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "def model_modifier_layer(current_model):\n",
        "    target_layer = current_model.get_layer(name='dense_1') #layer is the name of the intermediate layer\n",
        "    new_model = tf.keras.Model(inputs=current_model.inputs,\n",
        "                               outputs=target_layer.output)\n",
        "    new_model.layers[-1].activation = tf.keras.activations.linear\n",
        "    return new_model\n",
        "\n",
        "def loss_gen_sum(node_list):\n",
        "    def loss(output):\n",
        "        op = np.array(output)\n",
        "        \n",
        "        if (op.ndim > 2):\n",
        "          op = op.flatten()\n",
        "          output = np.empty((1,len(op)))\n",
        "          #print(output.shape)\n",
        "          output[0] = op\n",
        "         \n",
        "        #print(output.shape)\n",
        "        #print(output.ndim)\n",
        "        #print(output[0])#,op.ndim())\n",
        "        #fl_op = op.flatten()\n",
        "        #print(fl_op.shape)\n",
        "        loss_val = sum([output[0][i] for i in node_list])/len(node_list)\n",
        "        return loss_val\n",
        "    return loss\n",
        "\n",
        "\n",
        "def loss_gen_sum1(node_list):\n",
        "    def loss(output):\n",
        "        #print([output[0][i] for i in node_list])\n",
        "        #print(output.shape)\n",
        "        loss_val = sum([output[0][i] for i in node_list])/len(node_list)\n",
        "        return loss_val\n",
        "    return loss\n",
        "\n",
        "def loss_gen_sep(node):\n",
        "    def loss(output):\n",
        "        #print([output[0][i] for i in node_list])\n",
        "        loss_val = output[0][node]\n",
        "        return loss_val\n",
        "    return loss\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#from keras.models import load_model\n",
        "print('Loading the model:')\n",
        "model=load_model('cifar.hdf5')#,custom_objects={'smoothL1':smoothL1}) \n",
        "print(\"Printing summary of the model:\")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "layer_name = 'activation_5'\n",
        "lay = model.get_layer(layer_name)\n",
        "print(lay.get_config())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the model:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-eaac791f3c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;31m#from keras.models import load_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading the model:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#,custom_objects={'smoothL1':smoothL1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Printing summary of the model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: cifar.hdf5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZHqhkX4rUbN"
      },
      "source": [
        "def check_pattern(layer_vals,suff,neuron_ids,neuron_sig,VAL = False,ALL = False):\n",
        "   #layer = 'activation_3'  #layer name, get it from the model summary\n",
        "   #neuron_ids =  [-1,71,-1,20,-1,1,-1,28,-1,79,-1,29,-1,39,-1,49,-1,42,-1,33,-1,114,-1,117,-1,88,-1,31,-1,36,-1,33,-1,17,-1,117,-1,1,-1,28,-1,97] # neuron ids in the pattern\n",
        "   #neuron_sig =  ['>',0.435630053,'>',4.067234278,'<=',42.78802872,'<=',20.19964218,'<=',41.11421585,'<=',23.87646389,'<=',15.27161694,'<=',36.27468491,'<=',30.84732342,'<=',40.63782883,'<=',25.80421829,'<=',43.16035843,'<=',38.44324303,'<=',66.91875458,'<=',26.18983078,'<=',16.70914364,'<=',41.36343193,'<=',35.72474098,'<=',35.5690403,'<=',14.66370487,'<=',40.59473419189453]\n",
        "\n",
        "   if (VAL == False):\n",
        "      if ((suff[:,neuron_ids][0] == neuron_sig).all(axis=0)):\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "   found = True;\n",
        "  \n",
        "   oper = -1\n",
        "   for ind in range(0,len(neuron_ids)):\n",
        "     if (ind % 2 == 0):\n",
        "       op = neuron_sig[ind]\n",
        "       if (op == '<='):\n",
        "         oper = 0\n",
        "       else:\n",
        "         oper = 1\n",
        "     else:\n",
        "       v = int(neuron_ids[ind])\n",
        "       vsig = float(neuron_sig[ind])\n",
        "       val = layer_vals[v]\n",
        "       #print(v,vsig,val,oper)\n",
        "       if (oper == 0):\n",
        "         if (val > vsig):\n",
        "           found = False\n",
        "           break\n",
        "       else:\n",
        "         if (val <= vsig):\n",
        "            found = False\n",
        "            break\n",
        "       oper = -1\n",
        "\n",
        "   return found "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPuIvFyF3-6t"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "if (GENERATION_DATASETS == True):\n",
        "  a=[]\n",
        "  path = 'test_Y.txt'\n",
        "  inputfile = csv.reader(open(path,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "      c=[]\n",
        "      for i in range(0,len(row)):\n",
        "          c.append(int(row[i]))\n",
        "      a.append(c[0])\n",
        "  test_Y = np.array(a)\n",
        "  print(\"IDEAL LABELS:\", test_Y.shape)\n",
        "  print(test_Y[0])\n",
        "\n",
        "  a=[]\n",
        "  path = 'test_X.txt'\n",
        "  inputfile = csv.reader(open(path,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)):\n",
        "        c.append(float(row[i])/255.0)\n",
        "    c = np.reshape(c, (32,32,3))\n",
        "    a.append(c)\n",
        "  test_X = np.array(a)\n",
        "  print(\"CLEAN DATA:\", test_X.shape)\n",
        "\n",
        "\n",
        "  a=[]\n",
        "  path = 'backdoor_test_X.txt'\n",
        "  inputfile = csv.reader(open(path,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)):\n",
        "        c.append(float(row[i])/255.0)\n",
        "    c = np.reshape(c, (32,32,3))\n",
        "    a.append(c)\n",
        "  poisoned_x = np.array(a)\n",
        "  print(\"POISONED INPUTS:\", poisoned_x.shape)\n",
        "\n",
        "  poisoned_labels = (model.predict(poisoned_x)).argmax(axis=1)\n",
        "  PASS = 0\n",
        "  FAIL = 0\n",
        "  FAILP = 0\n",
        "  for indx in range(0, len(poisoned_labels)):\n",
        "    if (poisoned_labels[indx] == test_Y[indx]):\n",
        "      PASS = PASS + 1\n",
        "    else:\n",
        "      FAIL = FAIL + 1\n",
        "      if (poisoned_labels[indx]  == 7):\n",
        "        FAILP = FAILP+1\n",
        "  print(\"PASS:\", PASS, \",FAIL:\", FAIL, \",\", FAILP, \",POISONED ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "\n",
        "  test_labels = (model.predict(test_X)).argmax(axis=1)\n",
        "  PASS = 0\n",
        "  FAIL = 0\n",
        "  FAILP = 0\n",
        "  for indx in range(0, len(test_labels)):\n",
        "    if (test_labels[indx] == test_Y[indx]):\n",
        "      PASS = PASS + 1\n",
        "    else:\n",
        "      FAIL = FAIL + 1\n",
        "      if (test_labels[indx]  == 7):\n",
        "        FAILP = FAILP+1\n",
        "\n",
        "  print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\", FAILP ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBqWJ1Vc7qBq"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "if (GENERATION_DATASETS == True):\n",
        "  file_nm1 = \"CIFAR_GEN_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file1 = open(file_nm1, 'w')\n",
        "  file_nm1_lbl = \"CIFAR_GEN_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file1_lbl = open(file_nm1_lbl, 'w')\n",
        "\n",
        "  file_nm2= \"CIFAR_VAL_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file2 = open(file_nm2, 'w')\n",
        "  file_nm2_lbl= \"CIFAR_VAL_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file2_lbl = open(file_nm2_lbl, 'w')\n",
        "\n",
        "\n",
        "  indx_clean = []\n",
        "  len_test = (N/100.0) * len(test_labels)\n",
        "  while (len(indx_clean) < int(len_test)):\n",
        "    value = randint(0,len(test_labels)-1)\n",
        "    while (value in indx_clean):\n",
        "      value = randint(0,len(test_labels)-1)\n",
        "    indx_clean.append(value)\n",
        "\n",
        "\n",
        "  for indx in range(0,len(test_labels)):\n",
        "    if (indx in indx_clean):\n",
        "      #if(indx<100):\n",
        "      #    print(indx)\n",
        "      row = (test_X[indx]).flatten()\n",
        "      s = \"\"\n",
        "      for i in range(0,len(row)):\n",
        "        s = s +  str(row[i]) + \",\"\n",
        "      \n",
        "      file1.write(str(s) + \"\\n\")\n",
        "      file1_lbl.write(str(test_Y[indx]) + \"\\n\")\n",
        "    else:\n",
        "      row = (test_X[indx]).flatten()\n",
        "      s = \"\"\n",
        "      for i in range(0,len(row)):\n",
        "        s = s + str(row[i]) + \",\"\n",
        "      file2.write(str(s) + \"\\n\")\n",
        "      file2_lbl.write(str(test_Y[indx]) + \"\\n\")\n",
        "\n",
        "  indx_poison = []\n",
        "  len_poison = (N/100.0) * len(poisoned_labels)\n",
        "  while (len(indx_poison) < int(len_poison)):\n",
        "    value = randint(0,len(poisoned_labels)-1)\n",
        "    while (value in indx_poison):\n",
        "      value = randint(0,len(poisoned_labels)-1)\n",
        "    indx_poison.append(value)\n",
        "\n",
        "\n",
        "  for indx in range(0,len(poisoned_labels)):\n",
        "   if (indx in indx_poison):\n",
        "      #if(indx<100):\n",
        "          #print(indx)\n",
        "      row= (poisoned_x[indx]).flatten()\n",
        "      s = \"\"\n",
        "      for i in range(0,len(row)):\n",
        "        s = s + str(row[i]) + \",\"\n",
        "      file1.write(str(s) + \"\\n\")\n",
        "      file1_lbl.write(str(test_Y[indx]) + \"\\n\")\n",
        "   else:\n",
        "      row = (poisoned_x[indx]).flatten()\n",
        "      s = \"\"\n",
        "      for i in range(0,len(row)):\n",
        "        s = s + str(row[i]) + \",\"\n",
        "      file2.write(str(s) + \"\\n\")\n",
        "      file2_lbl.write(str(test_Y[indx]) + \"\\n\")\n",
        "\n",
        "  file1.close()\n",
        "  file1_lbl.close()\n",
        "  file2.close()\n",
        "  file2_lbl.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMnKY8LWt3R6"
      },
      "source": [
        "###################################CREATE ANOTHER FILES FROM NEWLY CREATED GENERATION DATASET FILE###########################################################\n",
        "\n",
        "if (further == True):\n",
        "  file_nm3 = str(NP)+ \"_\" +\"N_CIFAR_GEN_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file3 = open(file_nm3, 'w')\n",
        "  file_nm3_lbl = str(NP)+ \"_\" +\"N_CIFAR_GEN_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file3_lbl = open(file_nm3_lbl, 'w')\n",
        "  \n",
        "\n",
        "  counter=0\n",
        "  inputfile = csv.reader(open(file_nm1_lbl,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "      if(counter<5000):\n",
        "        s=\"\"\n",
        "        for i in range(0,len(row)):\n",
        "            s = s + str(row[i]) + \",\"\n",
        "        counter=counter+1\n",
        "        file3_lbl.write(s[:-1] + \"\\n\")\n",
        "  \n",
        "  counter=0\n",
        "  inputfile = csv.reader(open(file_nm1,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "      if(counter<5000):\n",
        "        s=\"\"\n",
        "        for i in range(0,len(row)):\n",
        "            s = s + str(row[i]) + \",\"\n",
        "        counter=counter+1\n",
        "        file3.write(s[:-1] + \"\\n\")\n",
        "\n",
        "  rand = []\n",
        "  len_test = (NP/100.0) * len(test_labels)/2\n",
        "  print(len_test)\n",
        "  while (len(rand) < int(len_test)):\n",
        "    value = randint(5001,len(test_labels))\n",
        "    while (value in rand):\n",
        "      value = randint(5001,len(test_labels))\n",
        "    rand.append(value)\n",
        "  print(len(rand))\n",
        "  print(rand)\n",
        "  \n",
        "  counter=0\n",
        "  inputfile = csv.reader(open(file_nm1_lbl,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "      counter=counter+1\n",
        "      if(counter in rand):\n",
        "        #print(counter)\n",
        "        s=\"\"\n",
        "        for i in range(0,len(row)):\n",
        "            s = s + str(row[i]) + \",\"\n",
        "        file3_lbl.write(s[:-1] + \"\\n\")\n",
        "  \n",
        "  counter=0\n",
        "  inputfile = csv.reader(open(file_nm1,'r')) # DEFINES THE INPUT FILE\n",
        "  for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "      counter=counter+1\n",
        "      if(counter in rand):\n",
        "        #print(counter)\n",
        "        s=\"\"\n",
        "        for i in range(0,len(row)):\n",
        "            s = s + str(row[i]) + \",\"\n",
        "        file3.write(s[:-1] + \"\\n\")\n",
        "  file3.close()\n",
        "  file3_lbl.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ISEE-wU7zFm"
      },
      "source": [
        "gen_data = []\n",
        "gen_labels = []\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "file_num1=\"\"\n",
        "file_nm1_lbl=\"\"\n",
        "\n",
        "if(further2==True):\n",
        "  file_nm1 = str(NP)+\"_N_CIFAR_GEN_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file_nm1_lbl = str(NP)+\"_N_CIFAR_GEN_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "else:\n",
        "  file_nm1 = \"CIFAR_GEN_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "  file_nm1_lbl = \"CIFAR_GEN_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "file_nm2= \"CIFAR_VAL_SET_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "file_nm2_lbl= \"CIFAR_VAL_SET_LABELS_\" + str(N) + \"_\" + str(num_run) + \".txt\"\n",
        "\n",
        "\n",
        "a=[]\n",
        "inputfile = csv.reader(open(file_nm1_lbl,'r')) # DEFINES THE INPUT FILE\n",
        "for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)):\n",
        "        c.append(int(row[i]))\n",
        "    a.append(c[0])\n",
        "gen_labels = np.array(a)\n",
        "print(\"GEN LABELS:\", gen_labels.shape)\n",
        "\n",
        "\n",
        "a=[]\n",
        "inputfile = csv.reader(open(file_nm1,'r')) # DEFINES THE INPUT FILE\n",
        "for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)-1):\n",
        "        c.append(float(row[i]))\n",
        "    c = np.reshape(c, (32,32,3))\n",
        "    a.append(c)\n",
        "gen_data = np.array(a)\n",
        "print(\"GEN DATA:\", gen_data.shape)\n",
        "\n",
        "actuals_gen = (model.predict(gen_data)).argmax(axis=1)\n",
        "print(\"ACT GENs:\", actuals_gen.shape)\n",
        "\n",
        "\n",
        "a=[]\n",
        "inputfile = csv.reader(open(file_nm2_lbl,'r')) # DEFINES THE INPUT FILE\n",
        "for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)):\n",
        "        c.append(int(row[i]))\n",
        "    a.append(c[0])\n",
        "val_labels = np.array(a)\n",
        "print(\"VAL LABELS:\", val_labels.shape)\n",
        "\n",
        "a=[]\n",
        "inputfile = csv.reader(open(file_nm2,'r')) # DEFINES THE INPUT FILE\n",
        "for row in inputfile: # TRAVERSES ALL ROWS OF DATA\n",
        "    c=[]\n",
        "    for i in range(0,len(row)-1):\n",
        "        c.append(float(row[i]))\n",
        "    c = np.reshape(c, (32,32,3))\n",
        "    a.append(c)\n",
        "val_data = np.array(a)\n",
        "print(\"VAL DATA:\", val_data.shape)\n",
        "\n",
        "actuals_val = (model.predict(val_data)).argmax(axis=1)\n",
        "print(\"ACT VALs:\", actuals_val.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sFKcdfGhTV3"
      },
      "source": [
        "#layer_preds\n",
        "layer = model.get_layer('activation_5')\n",
        "func = K.function(model.input, [layer.output])\n",
        "outputs = func(gen_data)\n",
        "fingerprint = ((outputs[0] > 0.0).astype('int'))\n",
        "fingerprint1 = outputs[0]\n",
        "\n",
        "PASS_LABEL_0 = 0\n",
        "PASS_LABEL_1 = 0\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "\n",
        "val_vec = []\n",
        "val_vec_labels = []\n",
        "print(\"VALS from layer:\")\n",
        "for i in range(0,len(fingerprint1)):  \n",
        "  if (actuals_gen[i] == gen_labels[i]):\n",
        "    PASS = PASS + 1\n",
        "    val_vec.append(np.asarray((fingerprint1[i]).flatten()))\n",
        "    val_vec_labels.append(gen_labels[i])\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "    if(actuals_gen[i] == 0):\n",
        "       val_vec_labels.append(-1000)\n",
        "    else:\n",
        "       val_vec_labels.append(0-actuals_gen[i])\n",
        "    val_vec.append(np.asarray((fingerprint1[i]).flatten()))\n",
        "    \n",
        "\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "act_vec = []\n",
        "act_vec_labels = []\n",
        "gen_fail_labels = []\n",
        "FAILP_GEN = 0\n",
        "print(\"ACTS from layer:\")\n",
        "\n",
        "\n",
        "for i in range(0,len(fingerprint)):\n",
        "  if (actuals_gen[i] == gen_labels[i]):\n",
        "    PASS = PASS + 1\n",
        "    act_vec_labels.append(gen_labels[i])\n",
        "    act_vec.append(np.asarray((fingerprint[i]).flatten()))\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "    act_vec.append(np.asarray((fingerprint[i]).flatten()))\n",
        "    if(actuals_gen[i] == 0):\n",
        "       act_vec_labels.append(-1000)\n",
        "    else:\n",
        "       act_vec_labels.append(0-actuals_gen[i])\n",
        "    if (actuals_gen[i]  == 7):\n",
        "      FAILP_GEN = FAILP_GEN +1\n",
        "   \n",
        "print(\"GENERATION SET FAIL:\", FAIL,\",POISONED:\", FAILP_GEN, \",ACCURACY:\" , (PASS/(PASS+FAIL))*100.0)\n",
        "\n",
        "\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "FAILP_VAL = 0\n",
        "for i in range(0,len(val_data)):\n",
        "  if (actuals_val[i] == val_labels[i]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "    if (actuals_val[i]  == 7):\n",
        "      FAILP_VAL = FAILP_VAL +1\n",
        "    \n",
        "\n",
        "print(\"VALIDATION SET FAIL:\", FAIL, \",POISONED:\", FAILP_VAL, \",ACCURACY:\" , (PASS/(PASS+FAIL))*100.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2T7Sv6dlbxJ"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "\n",
        "val_vec = np.asarray(val_vec)\n",
        "val_vec_labels = np.asarray(val_vec_labels)\n",
        "print(val_vec.shape, val_vec_labels.shape)\n",
        "\n",
        "\n",
        "\n",
        "#act_vec = np.asarray(act_vec)\n",
        "#act_vec_labels = np.asarray(act_vec_labels)\n",
        "#print(act_vec.shape, act_vec_labels.shape)\n",
        "\n",
        "\n",
        "train_suffixes = val_vec\n",
        "train_predictions = val_vec_labels\n",
        "basic_estimator1 = tree.DecisionTreeClassifier()\n",
        "basic_estimator1.fit(val_vec, val_vec_labels)\n",
        "\n",
        "#train_suffixes = act_vec\n",
        "#train_predictions = act_vec_labels\n",
        "basic_estimator = tree.DecisionTreeClassifier()\n",
        "basic_estimator.fit(act_vec, act_vec_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thD-NUl6lmD3"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import operator\n",
        "import pandas as pd\n",
        "\n",
        "def get_decision_path(estimator, inp):\n",
        "  # Extract the decision path taken by an input as an ordered list of indices\n",
        "  # of the neurons that were evaluated.\n",
        "  # See: http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html\n",
        "  n_nodes = estimator.tree_.node_count\n",
        "  feature = estimator.tree_.feature\n",
        "\n",
        "  # First let's retrieve the decision path of each sample. The decision_path\n",
        "  # method allows to retrieve the node indicator functions. A non zero element of\n",
        "  # indicator matrix at the position (i, j) indicates that the sample i goes\n",
        "  # through the node j.\n",
        "  X_test = [inp]\n",
        "  node_indicator = estimator.decision_path(X_test)\n",
        "  # Similarly, we can also have the leaves ids reached by each sample.\n",
        "  leaf_id = estimator.apply(X_test)\n",
        "  # Now, it's possible to get the tests that were used to predict a sample or\n",
        "  # a group of samples. First, let's make it for the sample.\n",
        "  node_index = node_indicator.indices[node_indicator.indptr[0]:\n",
        "                                      node_indicator.indptr[1]]\n",
        "  neuron_ids = []\n",
        "  for node_id in node_index:\n",
        "    if leaf_id[0] == node_id:\n",
        "        continue\n",
        "    neuron_ids.append(feature[node_id])\n",
        "  return neuron_ids\n",
        "\n",
        "def get_suffix_cluster(neuron_ids, neuron_sig,suffixes=train_suffixes):\n",
        "  # Get the cluster of inputs that such that all inputs in the cluster\n",
        "  # have provided on/off signature for the provided neurons.\n",
        "  #\n",
        "  # The returned cluster is an array of indices (into mnist.train.images).\n",
        "  return np.where((suffixes[:, neuron_ids] == neuron_sig).all(axis=1))[0]\n",
        "\n",
        "def is_consistent_cluster(cluster, predictions):\n",
        "  # Check if all inputs within the cluster have the same prediction.\n",
        "  # 'cluster' is an array of input ids.\n",
        "  pred = predictions[cluster[0]]\n",
        "  for i in cluster:\n",
        "    if predictions[i] != pred:\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "\n",
        "\n",
        "def get_invariant_inp(estimator, ref_id, suffixes):\n",
        "  # Returns an invariant found w.r.t. the provided reference input\n",
        "  # Args\n",
        "  #  - inp: reference input, shape <784,>\n",
        "  # Returns:\n",
        "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
        "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
        "  #    the reference input on the on/off status of these neurons have the\n",
        "  #    same prediction as the reference input.\n",
        "  ref_img = mnist_inp_images[ref_id]\n",
        "  ref_suffix = suffixes[ref_id]\n",
        "  print('PREFIX',ref_suffix)\n",
        "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
        "  print('NEURON IDS',neuron_ids)\n",
        "  neuron_sig = ref_suffix[neuron_ids]\n",
        "  print('NEURON SIGNATURE',neuron_sig)\n",
        "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,suffixes)\n",
        "  imgs = []\n",
        "  cnt = 0\n",
        "  for indx1 in range(0,len(cluster)):\n",
        "    img = mnist.train.images(cluster[indx1])\n",
        "    fnd = 1\n",
        "    for i in range(0,len(img)):\n",
        "      if (ref_img[i] != img[i]):\n",
        "        fnd = 0\n",
        "        break\n",
        "    if (fnd == 1):\n",
        "        ref_id = cnt\n",
        "    cnt = cnt + 1\n",
        "    imgs.append(img)\n",
        "    \n",
        "  imgs_suffixes = fingerprint_signature(imgs,t_fc2)\n",
        "  ref_suffix = imgs_suffixes[ref_id]\n",
        "  print('PREFIX',ref_suffix)\n",
        "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
        "  print('NEURON IDS',neuron_ids)\n",
        "  neuron_sig = ref_suffix[neuron_ids]\n",
        "  print('NEURON SIGNATURE',neuron_sig)\n",
        "  cluster = get_suffix_cluster(neuron_ids, neuron_sig,imgs_suffixes)\n",
        "    \n",
        "  return cluster, neuron_ids, neuron_sig\n",
        "\n",
        "def get_invariant(estimator, ref_id):\n",
        "  # Returns an invariant found w.r.t. the provided reference input\n",
        "  # Args\n",
        "  #  - ref_id: Index (into mnist.train.images) of the reference input\n",
        "  # Returns:\n",
        "  #  - cluster: Indices of training inputs that satisfy the invariant\n",
        "  #  - neuron_id: A list of neurons such that all inputs that agree with\n",
        "  #    the reference input on the on/off status of these neurons have the\n",
        "  #    same prediction as the reference input.\n",
        "  ref_img = mnist.train.images[ref_id]\n",
        "  ref_suffix = train_suffixes[ref_id]\n",
        "  neuron_ids = get_decision_path(estimator, ref_suffix)\n",
        "  neuron_sig = ref_suffix[neuron_ids]\n",
        "  cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
        "  return cluster, neuron_ids, neuron_sig\n",
        "\n",
        "\n",
        "def get_all_invariants(estimator):\n",
        "  # Returns a dictionary mapping each decision tree prediction class\n",
        "  # to a list of invariants. Each invariant is specified as a triple:\n",
        "  # - neuron ids\n",
        "  # - neuron signature (for the neuron ids)\n",
        "  # - number of training samples that hit it\n",
        "  # The neuron ids and neuron signature can be supplied to get_suffix_cluster\n",
        "  # to obtain the cluster of training instances that hit the invariant.\n",
        "  def is_leaf(node):\n",
        "    return estimator.tree_.children_left[node] == estimator.tree_.children_right[node]\n",
        "\n",
        "  def left_child(node):\n",
        "    return estimator.tree_.children_left[node]\n",
        "\n",
        "  def right_child(node):\n",
        "    return estimator.tree_.children_right[node]\n",
        "  \n",
        "  def get_all_paths_rec(node):\n",
        "    # Returns a list of triples corresponding to paths\n",
        "    # in the decision tree. Each triple consists of\n",
        "    # - neurons encountered along the path\n",
        "    # - signature along the path\n",
        "    # - prediction class at the leaf\n",
        "    # - number of training samples that hit the path\n",
        "    # The prediction class and number of training samples\n",
        "    # are set to -1 when the leaf is \"impure\".\n",
        "    feature = estimator.tree_.feature\n",
        "    threshold = estimator.tree_.threshold\n",
        "    if is_leaf(node):\n",
        "      values = estimator.tree_.value[node][0]\n",
        "      if len(np.where(values != 0)[0]) == 1:\n",
        "        cl = estimator.classes_[np.where(values != 0)[0][0]]\n",
        "        nsamples = estimator.tree_.n_node_samples[node]\n",
        "      else:\n",
        "        # impure node\n",
        "        cl = -1\n",
        "        nsamples = -1\n",
        "      return [[[], [], cl, nsamples]]\n",
        "    # If it is not a leaf both left and right childs must exist\n",
        "   # paths = [[[feature[node]] + p[0], [0] + p[1], p[2], p[3]] for p in get_all_paths_rec(left_child(node))]\n",
        "   # paths += [[[feature[node]] + p[0], [1] + p[1], p[2], p[3]] for p in get_all_paths_rec(right_child(node))]\n",
        "    paths = [[[feature[node]] + p[0],['<='] + [threshold[node]] + p[1], p[2], p[3]] for p in get_all_paths_rec(left_child(node))]\n",
        "    paths += [[[feature[node]] + p[0],['>'] + [threshold[node]] + p[1], p[2], p[3]] for p in get_all_paths_rec(right_child(node))]\n",
        "    return paths\n",
        "  paths =  get_all_paths_rec(0)\n",
        "  print(\"Obtained all paths\")\n",
        "  invariants = {}\n",
        "  for p in tqdm(paths):\n",
        "    neuron_ids, neuron_sig, cl, nsamples = p\n",
        "    if cl not in invariants:\n",
        "      invariants[cl] = []\n",
        "    # cluster = get_suffix_cluster(neuron_ids, neuron_sig)\n",
        "    invariants[cl].append([neuron_ids, neuron_sig, nsamples])\n",
        "  for cl in invariants.keys():\n",
        "    invariants[cl] = sorted(invariants[cl], key=operator.itemgetter(2), reverse=True)\n",
        "  return invariants\n",
        "\n",
        "\n",
        "def describe_cluster(cluster, neuron_ids, show_samples=False):\n",
        "  neuron_sig = train_suffixes[cluster[0]][neuron_ids]\n",
        "  print(\"Num neurons in invariant\", len(neuron_ids))\n",
        "  print(\"Neuron id and signature\")\n",
        "  \n",
        "  for i in range(0,len(neuron_ids)):\n",
        "    print(\"id:\", neuron_ids[i], \"sig:\", neuron_sig[i])\n",
        "  \n",
        "  print(\"Cluster size: \", len(cluster))\n",
        "  print(\"Num misclassified\", len([i for i in cluster if is_misclassified(i)]))\n",
        "  if show_samples:\n",
        "    for i in range(10):\n",
        "      images = []\n",
        "      for j in range(10):\n",
        "        if 10*i + j >= len(cluster):\n",
        "          break\n",
        "        images.append(mnist_to_pil_img(mnist.train.images[cluster[10*i+j]]))\n",
        "      if len(images) > 0:\n",
        "        show_img(combine(images))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "def describe_invariants_all_labels(all_invariants,suffixes=train_suffixes,COMMON=False, DEC_PREFX= False):\n",
        "  invs_sel_neus = []\n",
        "  invs_sel_sig = []\n",
        "  invs_sel_supp = []\n",
        "  corr_invs_sel_labs = []\n",
        "  corr_invs_sel_neus = []\n",
        "  corr_invs_sel_sig = []\n",
        "  corr_invs_sel_supp = []\n",
        "\n",
        "  #for indx in range(0,10):\n",
        "  #  corr_invs_sel_neus.append(np.array(1))\n",
        "  \n",
        "  #for indx in range(0,10):\n",
        "  #  corr_invs_sel_sig.append(np.array(1))\n",
        "\n",
        "  #print((np.array(invs_sel_neus)).shape, (np.array(invs_sel_sig)).shape, corr_invs_sel_neus.shape, corr_invs_sel_sig.shape )\n",
        "  supp = 0\n",
        "  for cl, invs in all_invariants.items():\n",
        "   \n",
        "    for indx in range (0, len(invs)):\n",
        "      inv = invs[indx]\n",
        "      if (inv[2] <= 10):\n",
        "        continue\n",
        "      #print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"),Support:\",inv[2])\n",
        "      print(\"Class:\", cl, \"Support:\",inv[2])\n",
        "      if (cl == -7):\n",
        "        #if (supp < ((80/100) * FAILP_GEN)):\n",
        "        if (inv[2] >= ((10/100) * FAILP_GEN)):\n",
        "          invs_sel_neus.append(inv[0])\n",
        "          invs_sel_sig.append(inv[1])\n",
        "          invs_sel_supp.append(inv[2])\n",
        "          supp = supp + inv[2]\n",
        "      \n",
        "      if ((cl >= 0) and (cl not in corr_invs_sel_labs)):\n",
        "          corr_invs_sel_labs.append(cl)\n",
        "          corr_invs_sel_neus.append(inv[0])\n",
        "          corr_invs_sel_sig.append(inv[1])\n",
        "          corr_invs_sel_supp.append(inv[2])\n",
        "      \n",
        "      continue\n",
        "\n",
        "      cls = get_suffix_cluster(inv[0],inv[1],suffixes)\n",
        "      \n",
        "      neurons = inv[0]\n",
        "      signature = inv[1]\n",
        "\n",
        "      if (len(cls) <= 10):\n",
        "         continue\n",
        "\n",
        "     # fail_cnt = []\n",
        "     # fail_label = []\n",
        "     # pass_cnt = []\n",
        "     # for ind in range(0,len(cls)):\n",
        "     #   inp_indx = cls[ind]\n",
        "     #   if (FP[inp_indx] == 0):\n",
        "     #     fail_cnt.append(inp_indx)\n",
        "     #     fail_label.append(IDEAL[inp_indx])\n",
        "     #   else:\n",
        "     #     pass_cnt.append(inp_indx)\n",
        "          \n",
        "      #fail_perc = (fail_cnt/len(cls))\n",
        "      #if (inv[2] == 243):\n",
        "      #print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"),Support:\",inv[2],\",Pass:\",[i for i in pass_cnt],\",Mis:\",[i for i in fail_cnt] , \",Label:\",[i for i in fail_label]);\n",
        "      \n",
        "      print(\"Class:\", cl, \", Rule:(neurons:\",inv[0],\",signature:\",inv[1],\"),Support:\",inv[2])\n",
        "      #if (indx > 0):\n",
        "      #  break\n",
        "     # for ind in range(0, len(cls)):\n",
        "     #    print(cls[ind])\n",
        "      \n",
        "     # break\n",
        "      if (COMMON == True):\n",
        "          common_nodes(cls,suffixes)\n",
        "\n",
        "      if (DEC_PREFX == True):\n",
        "          decision_prefs(cls,suffixes)\n",
        "\n",
        "  return (invs_sel_neus, invs_sel_sig, invs_sel_supp, corr_invs_sel_labs, corr_invs_sel_neus, corr_invs_sel_sig, corr_invs_sel_supp)\n",
        "  \n",
        "def common_nodes(cls,suffixes):\n",
        "    cnt = 0\n",
        "    common = np.zeros(10,dtype=int)\n",
        "    prev = np.zeros(10,dtype=int)\n",
        "    \n",
        "    for indx in range(0, len(cls)):\n",
        "        i = cls[indx]\n",
        "        cnt = cnt + 1\n",
        "        for j in range(0,len(suffixes[i])):\n",
        "          if (common[j] == -1):\n",
        "             continue\n",
        "          if ((indx != 0) and (suffixes[i][j] != prev[j])):\n",
        "             common[j] = -1\n",
        "          else:\n",
        "             common[j] = suffixes[i][j]\n",
        "          prev[j] = suffixes[i][j]\n",
        "\n",
        "\n",
        "    print('COMMON NODES IN CLUSTER for CLASS:',cl,cnt)\n",
        "    com = []\n",
        "    for k in range(0,len(common)):\n",
        "        if (common[k] != -1):\n",
        "           com.append((k,common[k]))\n",
        "    print(com)\n",
        "\n",
        "    return\n",
        "    \n",
        "def decision_prefs(cls,suffixes):\n",
        "    images = mnist.train.images\n",
        "    imgsCom = []\n",
        "    imgs = []\n",
        "    for indx in range(0, len(cls)):\n",
        "        print('IMG:')\n",
        "        print(list(zip(images[cls[indx]])))\n",
        "        imgs.append(images[cls[indx]])\n",
        "        imgsCom.append(images[cls[indx]])\n",
        "            \n",
        "    dec_prefixes= fingerprint_signature(imgs,layer)\n",
        "    prefixes = []\n",
        "    for indx in range(0,len(dec_prefixes)):\n",
        "       dec_pref = dec_prefixes[indx]\n",
        "    \n",
        "       match = 0\n",
        "       for indx1 in range(0, len(prefixes)):\n",
        "          match = 1\n",
        "          for i in range(0,len(prefixes[indx1])):\n",
        "             if (dec_pref[i] != prefixes[indx1][i]):\n",
        "                match = 0\n",
        "                break\n",
        "          if (match == 1):\n",
        "             break\n",
        "    \n",
        "       if (match == 0):\n",
        "          prefixes.append(dec_pref)\n",
        "    \n",
        "    print('DECISION  IN CLUSTER for CLASS:',cl,cnt)\n",
        "    for k in range(0,len(prefixes)):\n",
        "      print(prefixes[k])\n",
        "\n",
        "    return\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLzB27-llqTF"
      },
      "source": [
        "#invariants = get_all_invariants(basic_estimator)\n",
        "#(Ainvs_sel_neus, Ainvs_sel_sig, Ainvs_sel_supp, Acorr_invs_sel_labs, Acorr_invs_sel_neus, Acorr_invs_sel_sig, Acorr_invs_sel_supp) = describe_invariants_all_labels(invariants)\n",
        "#print(\"ACTIVATION PATTERNS:\")\n",
        "#for indx in range(0, len(Ainvs_sel_neus)):\n",
        "#  print(Ainvs_sel_neus[indx], Ainvs_sel_sig[indx], Ainvs_sel_supp[indx])\n",
        "#for indx in range(0, len(Acorr_invs_sel_labs)):\n",
        "#  print(Acorr_invs_sel_labs[indx], Acorr_invs_sel_neus[indx], Acorr_invs_sel_sig[indx], Acorr_invs_sel_supp[indx])\n",
        "\n",
        "invariants = get_all_invariants(basic_estimator1)\n",
        "(invs_sel_neus, invs_sel_sig, invs_sel_supp, corr_invs_sel_labs, corr_invs_sel_neus, corr_invs_sel_sig, corr_invs_sel_supp) = describe_invariants_all_labels(invariants)\n",
        "print(\"VALUE BASED PATTERNS:\")\n",
        "for indx in range(0, len(invs_sel_neus)):\n",
        "  print(invs_sel_neus[indx], invs_sel_sig[indx], invs_sel_supp[indx])\n",
        "  #print(invs_sel_neus[indx], invs_sel_supp[indx])\n",
        "#for indx in range(0, len(corr_invs_sel_labs)):\n",
        "  #print(corr_invs_sel_labs[indx], corr_invs_sel_neus[indx], corr_invs_sel_sig[indx], corr_invs_sel_supp[indx])\n",
        "  #print(corr_invs_sel_labs[indx], corr_invs_sel_supp[indx])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI3Hd83WnsfL"
      },
      "source": [
        "# INVOKE FOR EVERY CORRECT LABEL\n",
        "def corr_match_pattern(layer_vals,suff,neuron_ids,neuron_sig):\n",
        "   max_match_cnt = -1\n",
        "   for ix in range(0,len(neuron_ids)):\n",
        "     match_cnt = 0\n",
        "     oper = -1\n",
        "     for ind in range(0,len(neuron_ids[ix])):\n",
        "       if (ind % 2 == 0):\n",
        "         op = neuron_sig[ix][ind]\n",
        "         if (op == '<='):\n",
        "           oper = 0\n",
        "         else:\n",
        "           oper = 1\n",
        "       else:\n",
        "         v = neuron_ids[ix][ind]\n",
        "         vsig = neuron_sig[ix][ind]\n",
        "         val = layer_vals[v]\n",
        "         # print(v,vsig,val,oper)\n",
        "         if (oper == 0):\n",
        "          if (val <= vsig):\n",
        "            match_cnt = match_cnt + 1\n",
        "         else:\n",
        "          if (val > vsig):\n",
        "            match_cnt = match_cnt + 1\n",
        "         oper = -1\n",
        "         \n",
        "     if (match_cnt > max_match_cnt):\n",
        "       max_match_cnt = match_cnt\n",
        "\n",
        "   return max_match_cnt  \n",
        "\n",
        "def check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL = True,ALL=False):\n",
        "   \n",
        "   if (VAL == False):\n",
        "      if ((suff[:,neuron_ids][0] == neuron_sig).all(axis=0)):\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "   \n",
        "   found = True;\n",
        "   oper = -1\n",
        "   layer_vals = (layer_vals).flatten()\n",
        "   \n",
        "   for ix in range(0,len(neuron_ids)):\n",
        "     found = True\n",
        "     for ind in range(0,len(neuron_ids[ix])):\n",
        "       if (ind % 2 == 0):\n",
        "         op = neuron_sig[ix][ind]\n",
        "         if (op == '<='):\n",
        "           oper = 0\n",
        "         else:\n",
        "           oper = 1\n",
        "       else:\n",
        "         v = neuron_ids[ix][ind]\n",
        "         vsig = neuron_sig[ix][ind]\n",
        "         val = layer_vals[v]\n",
        "         #print(oper, v, vsig, val)\n",
        "         if (oper == 0):\n",
        "          if (val > vsig):\n",
        "            found = False\n",
        "          #  print('False')\n",
        "            break\n",
        "         else:\n",
        "          if (val <= vsig):\n",
        "            found = False\n",
        "           # print('False')\n",
        "            break\n",
        "         oper = -1\n",
        "     if (found == True):\n",
        "       break \n",
        "\n",
        "   if (found == False):\n",
        "      return -1\n",
        "   else:\n",
        "     return ix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epFmDtuHxngZ"
      },
      "source": [
        "def check_pattern(layer_vals,suff,neuron_ids,neuron_sig,VAL = True,ALL=False):\n",
        "   #layer = 'activation_3'  #layer name, get it from the model summary\n",
        "   #neuron_ids =  [-1,71,-1,20,-1,1,-1,28,-1,79,-1,29,-1,39,-1,49,-1,42,-1,33,-1,114,-1,117,-1,88,-1,31,-1,36,-1,33,-1,17,-1,117,-1,1,-1,28,-1,97] # neuron ids in the pattern\n",
        "   #neuron_sig =  ['>',0.435630053,'>',4.067234278,'<=',42.78802872,'<=',20.19964218,'<=',41.11421585,'<=',23.87646389,'<=',15.27161694,'<=',36.27468491,'<=',30.84732342,'<=',40.63782883,'<=',25.80421829,'<=',43.16035843,'<=',38.44324303,'<=',66.91875458,'<=',26.18983078,'<=',16.70914364,'<=',41.36343193,'<=',35.72474098,'<=',35.5690403,'<=',14.66370487,'<=',40.59473419189453]\n",
        "\n",
        "   if (VAL == False):\n",
        "      if ((suff[:,neuron_ids][0] == neuron_sig).all(axis=0)):\n",
        "        return True\n",
        "      else:\n",
        "        return False\n",
        "\n",
        "   found = True;\n",
        "   #Integer v = null;\n",
        "\t#\t\t\tDouble vsig = null;\n",
        "\t#\t\t\tString op = null;\n",
        "\t#\t\t\tint oper = -1;\n",
        "   oper = -1\n",
        "   for ind in range(0,len(neuron_ids)):\n",
        "     if (ind % 2 == 0):\n",
        "       op = neuron_sig[ind]\n",
        "       if (op == '<='):\n",
        "         oper = 0\n",
        "       else:\n",
        "         oper = 1\n",
        "     else:\n",
        "       v = neuron_ids[ind]\n",
        "       vsig = neuron_sig[ind]\n",
        "       val = layer_vals[v]\n",
        "      # print(v,vsig,val,oper)\n",
        "       if (oper == 0):\n",
        "         if (val > vsig):\n",
        "           found = False\n",
        "           break\n",
        "       else:\n",
        "         if (val <= vsig):\n",
        "            found = False\n",
        "            break\n",
        "       oper = -1\n",
        "\n",
        "   return found "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD5Rx5SV3_AE"
      },
      "source": [
        "REPAIR = False\n",
        "VAL = True\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "#REM = [[] for i in range(len(invs_sel_neus[indx])]\n",
        "\n",
        "x = gen_data #gen_data\n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_gen #actuals_gen\n",
        "ideals = gen_labels #gen_labels\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "\n",
        "\n",
        "sum_pat = [ np.zeros((1,32,32),dtype=float) for i in range(len(invs_sel_neus)) ]\n",
        "cnt_pat = [ np.zeros((1),dtype=int) for i in range(len(invs_sel_neus)) ]\n",
        "REM2 = [[] for i in range(len(invs_sel_neus))]\n",
        "REM5 = [[] for i in range(len(invs_sel_neus))]\n",
        "REM10 = [[] for i in range(len(invs_sel_neus))]\n",
        "\n",
        "#print(np.shape(sum_pat), np.shape(cnt_pat), np.shape(REM))\n",
        "\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "   \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "       \n",
        "        model1 = Model(model.inputs,model.outputs)\n",
        "        gradcam = GradcamPlusPlus(model1,model_modifier=model_modifier_act5_layer,clone=True)\n",
        "         \n",
        "        img = np.zeros((32,32,3),dtype=float)\n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "              for iz in range(0,3):\n",
        "                img[ix][iy][iz] = (float(image[ix][iy][iz]))\n",
        "\n",
        "        img_mod = np.expand_dims(img,axis=0)\n",
        "       \n",
        "        loss_fn = loss_gen_sum1(inc_neuron_ids[match])\n",
        "     \n",
        "        cam = gradcam(loss_fn,img_mod,penultimate_layer=-1)\n",
        "\n",
        "        cam = normalize(cam)\n",
        "        sum_pat[match] = sum_pat[match] + cam\n",
        "        cnt_pat[match] = cnt_pat[match] + 1\n",
        "      \n",
        "        \n",
        "        cnt = cnt + 1\n",
        "\n",
        "        \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('TOTAL CNT:',cnt)\n",
        "\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "for index in range(0, len(invs_sel_neus) ):\n",
        "  print(\"PATTERN:\" , index, \",MATCHES #:\", cnt_pat[index])\n",
        "  if (cnt_pat[index] == 0):\n",
        "    continue\n",
        "\n",
        "  avg_pat = sum_pat[index]/cnt_pat[index]\n",
        "  subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "  f, ax = plt.subplots(**subplot_args)\n",
        "  ax.set_title('AVERAGE GRADCAM ACROSS ALL IMAGES SATIFYING THE PATTERN')\n",
        "  avg_pat1 = avg_pat.reshape(32,32)\n",
        "  ax.imshow(avg_pat1, cmap='jet', alpha=0.6)\n",
        "  vals = []\n",
        "  for ix in range(0,32):\n",
        "    for iy in range(0,32):\n",
        "      if (avg_pat[0][ix][iy] not in vals):\n",
        "        vals.append(avg_pat[0][ix][iy])\n",
        "           \n",
        "  vals.sort(reverse=True)\n",
        "  top_2_percent = int((2/100)*(len(vals)))\n",
        "  top_5_percent = int((5/100)*(len(vals)))\n",
        "  top_10_percent = int((10/100)*(len(vals)))\n",
        "  \n",
        "  threshold2 = vals[top_2_percent]\n",
        "  threshold5 = vals[top_5_percent]\n",
        "  threshold10 = vals[top_10_percent]\n",
        "  \n",
        "  print(\"LEN VALS=\",len(vals), \",top 5%=\",top_5_percent)\n",
        "  print(\"MAX=\",vals[0],\",Threshold=\",threshold2)\n",
        "  print(\"MAX=\",vals[0],\",Threshold=\",threshold5)\n",
        "  print(\"MAX=\",vals[0],\",Threshold=\",threshold10)\n",
        "\n",
        "  rem_pixels = []\n",
        "  for ix in range(0,32):\n",
        "    for iy in range(0,32):\n",
        "      if (avg_pat[0][ix][iy] >= threshold2):\n",
        "            min_x = ix-1\n",
        "            max_x = ix+1\n",
        "            if (min_x < 0):\n",
        "              min_x = 0\n",
        "            if (max_x > 31):\n",
        "              max_x = 31\n",
        "\n",
        "            min_y = iy-1\n",
        "            max_y = iy+1\n",
        "            if (min_y < 0):\n",
        "              min_y = 0\n",
        "            if (max_y > 31):\n",
        "              max_y = 31\n",
        "            \n",
        "            for i_x in range(min_x,max_x+1):\n",
        "              for i_y in range(min_y,max_y+1):\n",
        "                #print(\"REM:\",i_x,\",\",i_y)\n",
        "                rem_pixels.append((i_x,i_y))\n",
        "               \n",
        "  REM2[index] = rem_pixels\n",
        "\n",
        "  rem_pixels = []\n",
        "  for ix in range(0,32):\n",
        "    for iy in range(0,32):\n",
        "      if (avg_pat[0][ix][iy] >= threshold5):\n",
        "            min_x = ix-1\n",
        "            max_x = ix+1\n",
        "            if (min_x < 0):\n",
        "              min_x = 0\n",
        "            if (max_x > 31):\n",
        "              max_x = 31\n",
        "\n",
        "            min_y = iy-1\n",
        "            max_y = iy+1\n",
        "            if (min_y < 0):\n",
        "              min_y = 0\n",
        "            if (max_y > 31):\n",
        "              max_y = 31\n",
        "            \n",
        "            for i_x in range(min_x,max_x+1):\n",
        "              for i_y in range(min_y,max_y+1):\n",
        "                #print(\"REM:\",i_x,\",\",i_y)\n",
        "                rem_pixels.append((i_x,i_y))\n",
        "               \n",
        "  REM5[index] = rem_pixels\n",
        "\n",
        "  rem_pixels = []\n",
        "  for ix in range(0,32):\n",
        "    for iy in range(0,32):\n",
        "      if (avg_pat[0][ix][iy] >= threshold10):\n",
        "            min_x = ix-1\n",
        "            max_x = ix+1\n",
        "            if (min_x < 0):\n",
        "              min_x = 0\n",
        "            if (max_x > 31):\n",
        "              max_x = 31\n",
        "\n",
        "            min_y = iy-1\n",
        "            max_y = iy+1\n",
        "            if (min_y < 0):\n",
        "              min_y = 0\n",
        "            if (max_y > 31):\n",
        "              max_y = 31\n",
        "            \n",
        "            for i_x in range(min_x,max_x+1):\n",
        "              for i_y in range(min_y,max_y+1):\n",
        "                #print(\"REM:\",i_x,\",\",i_y)\n",
        "                rem_pixels.append((i_x,i_y))\n",
        "               \n",
        "  REM10[index] = rem_pixels\n",
        "  #print(\"REM MATCH:\")   \n",
        "  #print(REM[index])\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVnR3cLgOZZj"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(gen_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_gen \n",
        "ideals = gen_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM2), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM2[match])):\n",
        "                    (rem_ix,rem_iy) = REM2[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYmbVNMEOZl-"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(gen_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_gen \n",
        "ideals = gen_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM5), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM5[match])):\n",
        "                    (rem_ix,rem_iy) = REM5[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayjc59FHOZti"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(gen_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_gen \n",
        "ideals = gen_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM10), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM10[match])):\n",
        "                    (rem_ix,rem_iy) = REM10[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZikEf4JVOZ1b"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(val_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_val \n",
        "ideals = val_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM2), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM2[match])):\n",
        "                    (rem_ix,rem_iy) = REM2[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y72cvip9OZ_4"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(val_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_val \n",
        "ideals = val_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM5), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM5[match])):\n",
        "                    (rem_ix,rem_iy) = REM5[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbepBqC9OaMZ"
      },
      "source": [
        "import copy\n",
        "wrongsolve=0\n",
        "x = copy.deepcopy(val_data) \n",
        "cnt = 0\n",
        "correct = 0\n",
        "\n",
        "labels = actuals_val \n",
        "ideals = val_labels \n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "true_positives = 0\n",
        "true_negatives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "ss=\"\"\n",
        "for inp_cnt in range(0,len(x)): # x is the list of images in the dataset used to extract the mis-classification pattern\n",
        "    \n",
        "    image = x[inp_cnt]\n",
        "    label = labels[inp_cnt]\n",
        "    \n",
        "    inp = image \n",
        "  \n",
        "    if (VAL == False):\n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(Ainvs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(Ainvs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(Ainvs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(Ainvs_sel_sig)):\n",
        "          neuron_sig.append(Ainvs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = [] \n",
        "        suff = inc_suff\n",
        "        \n",
        "    else:\n",
        "     \n",
        "        inc_layer = 'activation_5'  #layer name, get it from the model summary\n",
        "        inc_suff = fingerprint_suffix_vals(inp, inc_layer)\n",
        "\n",
        "        neuron_ids =[]\n",
        "        inc_neuron_ids=[]\n",
        "        neuron_sig = []\n",
        "\n",
        "        for indx in range (0, len(invs_sel_neus)):\n",
        "          neu_ids = []\n",
        "          for indx1 in range (0, len(invs_sel_neus[indx])):\n",
        "              neu_ids.append(-1)\n",
        "              neu_ids.append(invs_sel_neus[indx][indx1])\n",
        "          neuron_ids.append(neu_ids)\n",
        "          inc_neuron_ids.append(invs_sel_neus[indx])\n",
        "\n",
        "        for indx in range (0, len(invs_sel_sig)):\n",
        "          neuron_sig.append(invs_sel_sig[indx])\n",
        "\n",
        "        layer_vals = inc_suff[0]\n",
        "        suff = []\n",
        "  \n",
        "    image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "    image_array[0]=image\n",
        "    \n",
        "    match = check_pattern_inter(layer_vals,suff,neuron_ids,neuron_sig,VAL,False)\n",
        "    if (match >= 0):\n",
        "        \n",
        "\n",
        "        print(\"IDENTIFIED POISONED INPUT\", inp_cnt,\",\", cnt, \",ACTUAL:\", labels[inp_cnt], \",IDEAL:\", ideals[inp_cnt])\n",
        "        \n",
        "        if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          false_positives = false_positives + 1\n",
        "        else:\n",
        "          true_positives = true_positives + 1\n",
        "      \n",
        "        if ( cnt == 100):\n",
        "                print(\"BEFORE REPAIR\",img.shape,image.shape)\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "                ss=\"\"\n",
        "                for i in range(0,32):\n",
        "                  for j in range(0,32):\n",
        "                    for k in range(0,3):\n",
        "                      ss=ss+str(image[i][j][k])+\",\"\n",
        "                \n",
        "\n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0] = image\n",
        "        label = (model.predict(image_array)).argmax(axis=1)\n",
        "\n",
        "        print(np.shape(REM10), match)  \n",
        "        for ix in range(0,32):\n",
        "            for iy in range(0,32):\n",
        "                fnd = 0\n",
        "                for rem in range(0,len(REM10[match])):\n",
        "                    (rem_ix,rem_iy) = REM10[match][rem]\n",
        "                    if (rem_ix == ix and rem_iy == iy):\n",
        "                      image[ix][iy][0]=0.0\n",
        "                      image[ix][iy][1]=0.0\n",
        "                      image[ix][iy][2]=0.0\n",
        "                      fnd = 1\n",
        "                      break\n",
        "              \n",
        "        if (cnt == 100):\n",
        "                print(\"AFTER REPAIR\")\n",
        "                subplot_args = { 'nrows': 1, 'ncols': 1, 'figsize': (12, 12),'subplot_kw': {'xticks': [], 'yticks': []} }\n",
        "                f, ax = plt.subplots(**subplot_args)\n",
        "                ax.set_title('REPAIRED IMAGE')\n",
        "                norm_img = np.zeros((32,32,3),dtype=float)\n",
        "                for ix in range(0,32):\n",
        "                  for iy in range(0,32):\n",
        "                    for iz in range(0,3):\n",
        "                      norm_img[ix][iy][iz] = (image[ix][iy][iz])\n",
        "                img1 = norm_img.reshape(32,32,3)\n",
        "                ax.imshow(img1)\n",
        "          \n",
        "        image_array = np.zeros((1,32,32,3),dtype=float)\n",
        "        image_array[0]=image\n",
        "        new_label = (model.predict(image_array)).argmax(axis=1)\n",
        "        if (labels[inp_cnt] == ideals[inp_cnt] and new_label != ideals[inp_cnt]):\n",
        "          wrongsolve=wrongsolve+1\n",
        "        print(\"OLD LABEL:\", label, \",REPAIRED LABEL:\", new_label, \",CORRECT LABEL:\", ideals[inp_cnt])\n",
        "        if ((ideals[inp_cnt] != label) and (ideals[inp_cnt] == new_label)):\n",
        "            correct = correct + 1\n",
        "        cnt = cnt + 1    \n",
        "    else:\n",
        "      if (labels[inp_cnt] == ideals[inp_cnt]):\n",
        "          true_negatives = true_negatives + 1\n",
        "      else:\n",
        "        if (labels[inp_cnt] == 7):\n",
        "          false_negatives = false_negatives + 1\n",
        "\n",
        "print('CNT:',cnt)\n",
        "\n",
        "print('TP:', true_positives, ',FP:', false_positives, \",TN:\", true_negatives, \",FN:\", false_negatives)\n",
        "PREC = ((true_positives)/ (true_positives + false_positives))\n",
        "RECALL = ((true_positives)/ (true_positives + false_negatives))\n",
        "print(\"PRECISION:\" , PREC * 100.0, \",RECALL:\", RECALL * 100.0)\n",
        "\n",
        "print('CORRECT:', correct)\n",
        "rep_rate = ((correct/true_positives) * 100.0)\n",
        "print(\"REPAIR RATE:\", rep_rate)\n",
        "print(ss)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "test_labels = (model.predict(x)).argmax(axis=1)\n",
        "PASS = 0\n",
        "FAIL = 0\n",
        "for indx in range(0, len(x)):\n",
        "  if (test_labels[indx] == ideals[indx]):\n",
        "    PASS = PASS + 1\n",
        "  else:\n",
        "    FAIL = FAIL + 1\n",
        "print(\"PASS:\", PASS, \",FAIL:\", FAIL,\",\" ,\",TEST ACCURACY:\", (PASS/(PASS+FAIL))*100.0)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(wrongsolve)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}